# Stay Awake AI üò¥‚û°Ô∏èüü¢

A pipeline for **camera-based drowsiness detection**: model training, **TFLite** export, and **real-time inference** (video/webcam), plus lightweight log analysis.

> This repo targets the stack in `requirements.txt` (e.g., TensorFlow 2.20, OpenCV 4.12, PyTorch 2.8 CUDA 12.x). Adjust as needed for your machine (CPU-only vs GPU).

---

## ‚ú® Features

- **Training**: Train a drowsiness classifier on facial cues.
- **Inference**:
  - Real-time webcam or video file with TFLite  
  - Thresholding, label mapping, smoothing options
- **Analysis**: Read CSV prediction logs and plot quick stats.

---

## üìö Dataset

This project uses the Kaggle **Drowsy Detection Dataset** by *Yashar Jebraeily*:

- Dataset: https://www.kaggle.com/datasets/yasharjebraeily/drowsy-detection-dataset

> Make sure to follow the dataset‚Äôs license/usage terms. If you publish results, please cite the dataset accordingly.

---

## üì¶ Environment

### 1) Create a virtual environment
```bash
python -m venv .venv
# macOS/Linux
source .venv/bin/activate
# Windows
# .venv\Scripts\activate
```

### 2) Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Notes**
- Key packages (from `requirements.txt`):
  - TensorFlow 2.20.x (+ `tf_keras`), OpenCV 4.12, Pandas/Matplotlib
  - PyTorch 2.8.0 + CUDA 12.9 build, torchvision 0.23.0 + CUDA 12.9
  - NVIDIA CUDA 12.x user-space libs (for GPU setups)
- **CPU-only** users: install CPU wheels (e.g., `torch==2.8.0+cpu`) or remove CUDA-specific entries.

---

## üóÇÔ∏è Project Layout (example)

```
stay_awake_ai/
‚îú‚îÄ dataset/                 # Your dataset root (train/val/test or similar)
‚îú‚îÄ export/                  # Training outputs (checkpoints, logs)
‚îú‚îÄ export_tflite/           # TFLite artifacts (.tflite, labels.json)
‚îú‚îÄ train.py                 # Training script
‚îú‚îÄ export_tflite.py         # TFLite conversion script
‚îú‚îÄ tflite_test.py           # TFLite inference (video/webcam)
‚îú‚îÄ analyze.py               # CSV log analysis & plots
‚îî‚îÄ requirements.txt
```

---

## üöÄ Quickstart

### A) Real-time / video inference with **TFLite**
```bash
# video file
python tflite_test.py export_to_tflite/drowsy_fp16.tflite export/labels.json input.mp4 --show

# webcam (index 0) + mirrored preview
python tflite_test.py export_to_tflite/drowsy_fp16.tflite export/labels.json --camera 0 --show --flip
```
Common flags:
- `--decision-thr 0.8` ‚Üí classify as DROWSY if p‚â•0.8  
- `--drowsy-label DROWSY` ‚Üí label name for positive class  
- `--no-csv` ‚Üí disable CSV logging

### B) Analyze predictions
```bash
python analyze.py ./result/Non_Drowsy.csv --plot
```

### C) Train a model
```bash
python train.py \
  --data-root ./dataset \
  --epochs 20 \
  --batch-size 32 \
  --img-size 224 \
  --out ./export
```

### D) Export to **TFLite**
```bash
python export_tflite.py \
  --ckpt ./export/best_model.h5 \
  --out ./export_tflite/drowsy_fp16.tflite \
  --quantize fp16
```

> Check each script‚Äôs `--help` for the exact argument set implemented in your repo.

---

## üîß Troubleshooting

- **Webcam not found**: try `--camera 0/1/2‚Ä¶`
- **Low FPS**: lower input resolution, use FP16/INT8 quantization, or frame-skip
- **Label / preprocessing mismatch**: ensure train & inference use identical resize/normalize rules
- **CUDA mismatch**: match driver/toolkit and wheels; on servers without proper CUDA, switch to CPU wheels

---

## üó∫Ô∏è Roadmap (example)

- [ ] **Late Fusion**: combine camera predictions with smartwatch heart-rate (post-hoc fusion)
- [ ] **Log pairing**: auto-pair face/HR logs at the same timestamps ‚Üí build a paired dataset
- [ ] **Early/Hybrid Fusion**: train a multimodal model once paired data is collected

---

## ü§ù Contributing

Issues and PRs are welcome. Please include:
- exact commands you ran
- environment info (OS, Python, GPU/CPU)
- minimal repro data paths (or synthetic samples)
